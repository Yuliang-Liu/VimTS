<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization">
  <meta name="keywords" content="cross-domain text spotting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VimTS</title>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://cdn-icons-png.flaticon.com/512/954/954591.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.16.0/gradio.js"></script>
</head>

<style>
  .expandable-card .card-text-container {
    max-height: 200px;
    overflow-y: hidden;
    position: relative;
  }

  .expandable-card.expanded .card-text-container {
    max-height: none;
  }

  .expand-btn {
    position: relative;
    display: none;
    background-color: rgba(255, 255, 255, 0.8);
    /* margin-top: -20px; */
    /* justify-content: center; */
    color: #510c75;
    border-color: transparent;
  }

  .expand-btn:hover {
    background-color: rgba(200, 200, 200, 0.8);
    text-decoration: none;
    border-color: transparent;
    color: #510c75;
  }

  .expand-btn:focus {
    outline: none;
    text-decoration: none;
  }

  .expandable-card:not(.expanded) .card-text-container:after {
    content: "";
    position: absolute;
    bottom: 0;
    left: 0;
    width: 100%;
    height: 90px;
    background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
  }

  .expandable-card:not(.expanded) .expand-btn {
    margin-top: -40px;
  }

  .card-body {
    padding-bottom: 5px;
  }

  .vertical-flex-layout {
    justify-content: center;
    align-items: center;
    height: 100%;
    display: flex;
    flex-direction: column;
    gap: 5px;
  }

  .figure-img {
    max-width: 100%;
    height: auto;
  }

  .adjustable-font-size {
    font-size: calc(0.5rem + 2vw);
  }

  .chat-history {
    flex-grow: 1;
    overflow-y: auto;
    /* overflow-x: hidden; */
    padding: 5px;
    border-bottom: 1px solid #ccc;
    margin-bottom: 10px;
  }

  #gradio pre {
    background-color: transparent;
  }
</style>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">VimTS: <span class="is-size-2"><span class="is-size-1">A</span> <span class="is-size-1"></span>U</span>nified <span class="is-size-1">V</span>ideo <span class="is-size-1">a</span>nd <span class="is-size-1">I</span>mage <span class="is-size-1">T</span>ext</span> <span class="is-size-1">S</span>potter</span> <span class="is-size-1">f</span>or <span class="is-size-1">E</span>nhancing</span> <span class="is-size-1">t</span>he <span class="is-size-1">C</span>ross-domain</span> <span class="is-size-1">G</span>eneralization</span></h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Yuliang Liu</a>,
              </span>
              <span class="author-block">
                <a style="color:#008AD7;font-weight:normal;">Mingxin Huang</a>,
              </span>
              <span class="author-block">
                <a style="color:#F2A900;font-weight:normal;">Hao Yan</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Linger Deng</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Weijia Wu</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Hao Lu</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Chunhua Shen</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Lianwen Jin</a>,
              </span>
              <span class="author-block">
                <a style="color:#f68946;font-weight:normal;">Xiang Bai</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> Huazhong University of Science and Technology</b></span>
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> South China University of Technology</span>
              <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b> Zhejiang University</span>
            </div>


            
          <!-- <div class="column has-text-centered">
            <h3 class="title is-3 publication-title">Improved Baselines with Visual Instruction Fine-tuning</h3>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://hliu.cc/" style="color:#f68946;font-weight:normal;">Haotian Liu<sup>*</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://chunyuan.li/" style="color:#008AD7;font-weight:normal;">Chunyuan Li<sup>*</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://yuheng-li.github.io" style="color:#008AD7;font-weight:normal;">Yuheng Li</a>,
              </span>
              <span class="author-block">
                <a href="https://pages.cs.wisc.edu/~yongjaelee/" style="color:#f68946;font-weight:normal;">Yong Jae
                  Lee</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> University of
                Wisconsin-Madison</b></span>
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> Microsoft Research</span>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.08485" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-centered">
          ðŸ”¥<span style="color: #ff3860">
          VimTS is a unified video and image text spotter for enhancing the cross-domain generalization. It outperforms the state-of-the-art method by an average of 2.6% in six cross-domain benchmarks such as TT-to-IC15, CTW1500-to-TT, and TT-to-CTW1500. For video-level cross-domain adaption, our method even surpasses the previous end-to-end video spotting method in ICDAR2015 video and DSText v2 by an average of 5.5% on the MOTA metric, using only image-level data.
        </h4>
      </div>
    </div>
  </section>

  <section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We introduce a new method, termed VimTS, which enhances the generalization ability of the model by achieving better synergy among different tasks.
              <ol type="1">
                <li><b>Unified Framework </b>. <span style="font-size: 95%;"> VimTS is a unified framework capable of performing both word-level and line-level text spotting, as well as video-level text spotting.
                <li><b>VTD-368k</b>. <span style="font-size: 95%;"> By utilizing the CoDeF to facilitate the achievement of realistic and stable text flow propagation, we propose a synthetic video text dataset (VTD-368k).
                <li><b>Performance</b>. <span style="font-size: 95%;">Existing Large Multimodal Models exhibit limitations in generating cross-domain scene text spotting, in contrast to our VimTS model which requires significantly fewer parameters and data.
              </ol>  
           </p>
  
          </div>
        </div>
      </div>
        
    </div>
  </section>

<!-- <section class="section">
  <!-- Results. -->
  <!-- <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5886/5886212.png"> Cross-doamin Issue</h2>
    </div>
  </div> -->
  <!-- </div> -->
  <!--/ Results. -->    
<!-- <div class="container is-max-desktop"> -->

  <!-- <div class="columns is-centered"> -->
    <!-- <div class="column is-full-width"> -->
        <!-- <div class="row">
          <div class="column">
            <img src="images/I-cross.png" alt="Snow" style="width:80%; height: 300px;">
          </div>
          <div class="column">
            <img src="images/V-cross.png" alt="Forest" style="width:75%; height: 200px;">
          </div>
        </div> -->

        <!-- <div class="content has-text-justified"> -->
        <!-- <p> -->
          <!-- In real world applications, cross-domain end-to-end text spotting is usually encountered. In this paper, we focus on two types of cross-domain text spotting, including image-to-image and image-to-video. -->
          <!-- <figure style="text-align: center;">
            <img id="teaser" width="50%" src="images/I-cross.png">  
          </figure>
          <figure style="text-align: center;">
            <img id="teaser" width="50%" src="images/V-cross.png">  
          </figure>
        <p> -->
<!-- CSS Code: Place this code in the document's head (between the 'head' tags)   -->
      <!-- </div>
    </div>
  </div>
</section> -->

<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5886/5886212.png"> Framework</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">

  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified">
        <p>
          Overall framework of our method.
          <figure style="text-align: center;">
            <img id="teaser" width="100%" src="images/framework.png">  
          </figure>
        </p>
        <p>
          Overall framework of CoDeF-based synthetic method.
          <figure style="text-align: center;">
            <img id="teaser" width="80%" src="images/flowtext.png">  
          </figure>
        </p>
<!-- CSS Code: Place this code in the document's head (between the 'head' tags) -->  
      </div>
    </div>
  </div>
</section>
  
<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5886/5886212.png"> VTD-368k</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">

  <div class="columns is-centered">
    <div class="column is-full-width">
      <div class="content has-text-justified">
        <p>
          We manually collect and filter text-free, open-source and unrestricted videos from NExT-QA, Charades-Ego, Breakfast, A2D, MPI-Cooking, ActorShift and Hollywood. By utilizing the CoDeF, our synthetic method facilitates the achievement of realistic and stable text flow propagation, significantly reducing the occurrence of distortions.
          <figure style="text-align: center;">
            <img id="teaser" width="100%" src="images/VTD-368k.png">  
          </figure>
<!-- CSS Code: Place this code in the document's head (between the 'head' tags) -->  
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmar Experiments</h2>
        <div class="content has-text-justified">
        <p>
          For image-level cross-domain text spotting, we conduct experiments on six cross-domain scenarios to evaluate VimTS. 
          For video-level cross-domain text spotting, we conduct experiments on two popular video text spotting benchmarks to evaluate VimTS. 
          The results are presented in the following.
          
        </p>
        <p>
        <div align=center>
          <img src="images/cd_det.png" style="width: 100%" alt>
        </div>
        <div align=center>
          <img src="images/cd_e2e.png" style="width: 100%" alt>
        </div>
        <div align=center>
          <img src="images/cd_video.png" style="width: 100%" alt>
        </div>
        <div align=center>
          <img src="images/cp_mlmms.png" style="width: 55%" alt>
        </div>
        </p>
        <ul>
          <li> 
            <b>Conclusion: It is worth mentioning that our method demonstrates it is viable that still text images can be 
              learned to be well transferred to video text images. Since still images require significantly less annotation 
              effort compared to video image, exploring methods to bridge the domain gaps will be highly valuable. 
              Furthermore, we demonstrate that current Large Multimodal Models still face limitations in cross-domain text 
              spotting. Using fewer parameters and less data to improve the generalization of Large Multimodal Models in 
              text spotting is worth further exploration.
          </li>
        </ul>
        </div>
      </div>
    </div>
</section>



<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/5886/5886212.png"> Some Visualization</h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">

  <div class="columns is-centered">
    <div class="column is-full-width">
      <div align=center>
        <img src="images/vis.png" style="width: 70%" alt>
      </div>
    </div>
<!-- CSS Code: Place this code in the document's head (between the 'head' tags) -->  
  </div>
    </div>
  </div>
</section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
  @misc{liuvimts,
          author={Liu, Yuliang and Huang, Mingxin and Yan, Hao and Deng, Linger and Wu, Weijia and Lu, Hao and Shen, Chunhua and Jin, Lianwen and Bai, Xiang},
          title={VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization}, 
          publisher={arXiv:xxxxxx},
          year={2024},
  }
  </code></pre>
    </div>
  </section>

</body>

</html>
